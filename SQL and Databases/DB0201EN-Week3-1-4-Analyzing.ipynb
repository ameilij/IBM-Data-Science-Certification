{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDB0201ENSkillsNetwork20127838-2022-01-01\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n    </a>\n</p>\n\n# Analyzing a real world data-set with SQL and Python\n\nEstimated time needed: **15** minutes\n\n## Objectives\n\nAfter completing this lab you will be able to:\n\n*   Understand a dataset of selected socioeconomic indicators in Chicago\n*   Learn how to store data in an Db2 database on IBM Cloud instance\n*   Solve example problems to practice your SQL skills\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Selected Socioeconomic Indicators in Chicago\n\nThe city of Chicago released a dataset of socioeconomic data to the Chicago City Portal.\nThis dataset contains a selection of six socioeconomic indicators of public health significance and a \u201chardship index,\u201d for each Chicago community area, for the years 2008 \u2013 2012.\n\nScores on the hardship index can range from 1 to 100, with a higher index number representing a greater level of hardship.\n\nA detailed description of the dataset can be found on [the city of Chicago's website](https://data.cityofchicago.org/Health-Human-Services/Census-Data-Selected-socioeconomic-indicators-in-C/kn9c-c2s2?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDB0201ENSkillsNetwork20127838-2022-01-01), but to summarize, the dataset has the following variables:\n\n*   **Community Area Number** (`ca`): Used to uniquely identify each row of the dataset\n\n*   **Community Area Name** (`community_area_name`): The name of the region in the city of Chicago\n\n*   **Percent of Housing Crowded** (`percent_of_housing_crowded`): Percent of occupied housing units with more than one person per room\n\n*   **Percent Households Below Poverty** (`percent_households_below_poverty`): Percent of households living below the federal poverty line\n\n*   **Percent Aged 16+ Unemployed** (`percent_aged_16_unemployed`): Percent of persons over the age of 16 years that are unemployed\n\n*   **Percent Aged 25+ without High School Diploma** (`percent_aged_25_without_high_school_diploma`): Percent of persons over the age of 25 years without a high school education\n\n*   **Percent Aged Under** 18 or Over 64:Percent of population under 18 or over 64 years of age (`percent_aged_under_18_or_over_64`): (ie. dependents)\n\n*   **Per Capita Income** (`per_capita_income_`): Community Area per capita income is estimated as the sum of tract-level aggragate incomes divided by the total population\n\n*   **Hardship Index** (`hardship_index`): Score that incorporates each of the six selected socioeconomic indicators\n\nIn this Lab, we'll take a look at the variables in the socioeconomic indicators dataset and do some basic analysis with Python.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Connect to the database\n\nLet us first load the SQL extension and establish a connection with the database\n\nThe following required modules are pre-installed in the Skills Network Labs environment. However if you run this notebook commands in a different Jupyter environment (e.g. Watson Studio or Ananconda) you may need to install these libraries by removing the `#` sign before `!pip` in the code cell below.\n"}, {"metadata": {}, "cell_type": "code", "source": "# These libraries are pre-installed in SN Labs. If running in another environment please uncomment lines below to install them:\n!pip install --force-reinstall ibm_db==3.1.0 ibm_db_sa==0.3.3\n# Ensure we don't load_ext with sqlalchemy>=1.4 (incompadible)\n!pip uninstall sqlalchemy==1.4 -y && pip install sqlalchemy==1.3.24\n!pip install ipython-sql", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "Collecting ibm_db==3.1.0\n  Downloading ibm_db-3.1.0.tar.gz (797 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 797 kB 20.9 MB/s eta 0:00:01\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n\u001b[?25hCollecting ibm_db_sa==0.3.3\n  Downloading ibm_db_sa-0.3.3.tar.gz (24 kB)\nCollecting sqlalchemy>=0.7.3\n  Downloading SQLAlchemy-1.4.42-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.6 MB 74.0 MB/s eta 0:00:01\n\u001b[?25hCollecting greenlet!=0.4.17\n  Downloading greenlet-1.1.3.post0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (154 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 154 kB 83.9 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: ibm-db, ibm-db-sa\n  Building wheel for ibm-db (PEP 517) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ibm-db: filename=ibm_db-3.1.0-cp39-cp39-linux_x86_64.whl size=267214 sha256=380aa64f109bc6bf5e877254e9834b07fd70fdee2f7c39ff1ff65e9a470ddac9\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/0a/dd/10/4a9ad59949e39786d729813e4bce24ccf2263c6d60a62de2f2\n  Building wheel for ibm-db-sa (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ibm-db-sa: filename=ibm_db_sa-0.3.3-py3-none-any.whl size=27427 sha256=7c546d007d3324ec5552e20a7102db5fc613f52dafb8271c0784df8e8349c66f\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/8f/98/0c/930c68279890092297e12d4cc20e95613ddab15af6753d92bb\nSuccessfully built ibm-db ibm-db-sa\nInstalling collected packages: greenlet, sqlalchemy, ibm-db-sa, ibm-db\n  Attempting uninstall: greenlet\n    Found existing installation: greenlet 1.1.1\n    Uninstalling greenlet-1.1.1:\n      Successfully uninstalled greenlet-1.1.1\n  Attempting uninstall: sqlalchemy\n    Found existing installation: SQLAlchemy 1.4.27\n    Uninstalling SQLAlchemy-1.4.27:\n      Successfully uninstalled SQLAlchemy-1.4.27\n  Attempting uninstall: ibm-db-sa\n    Found existing installation: ibm-db-sa 0.3.7\n    Uninstalling ibm-db-sa-0.3.7:\n      Successfully uninstalled ibm-db-sa-0.3.7\n  Attempting uninstall: ibm-db\n    Found existing installation: ibm-db 3.1.0\n    Uninstalling ibm-db-3.1.0:\n      Successfully uninstalled ibm-db-3.1.0\nSuccessfully installed greenlet-1.1.3.post0 ibm-db-3.1.0 ibm-db-sa-0.3.3 sqlalchemy-1.4.42\nFound existing installation: SQLAlchemy 1.4.42\nUninstalling SQLAlchemy-1.4.42:\n  Successfully uninstalled SQLAlchemy-1.4.42\nCollecting sqlalchemy==1.3.24\n  Downloading SQLAlchemy-1.3.24-cp39-cp39-manylinux2010_x86_64.whl (1.3 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.3 MB 21.9 MB/s eta 0:00:01\n\u001b[?25hInstalling collected packages: sqlalchemy\nSuccessfully installed sqlalchemy-1.3.24\nCollecting ipython-sql\n  Downloading ipython_sql-0.4.1-py3-none-any.whl (21 kB)\nCollecting sqlparse\n  Downloading sqlparse-0.4.3-py3-none-any.whl (42 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 42 kB 3.5 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: six in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython-sql) (1.15.0)\nRequirement already satisfied: sqlalchemy>=0.6.7 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython-sql) (1.3.24)\nRequirement already satisfied: ipython-genutils>=0.1.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython-sql) (0.2.0)\nRequirement already satisfied: ipython>=1.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython-sql) (7.29.0)\nCollecting prettytable<1\n  Downloading prettytable-0.7.2.zip (28 kB)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (3.0.20)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (0.18.0)\nRequirement already satisfied: pygments in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (2.10.0)\nRequirement already satisfied: setuptools>=18.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (58.0.4)\nRequirement already satisfied: traitlets>=4.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (5.1.1)\nRequirement already satisfied: matplotlib-inline in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (0.1.2)\nRequirement already satisfied: pickleshare in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (0.7.5)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (4.8.0)\nRequirement already satisfied: backcall in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (0.2.0)\nRequirement already satisfied: decorator in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (5.1.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from jedi>=0.16->ipython>=1.0->ipython-sql) (0.8.3)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pexpect>4.3->ipython>=1.0->ipython-sql) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=1.0->ipython-sql) (0.2.5)\nBuilding wheels for collected packages: prettytable\n  Building wheel for prettytable (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for prettytable: filename=prettytable-0.7.2-py3-none-any.whl size=13714 sha256=f3beea1c4af0bfa8c9bc596c17a2d7811f62ac0448c36f4b34e467443b64d4d5\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/75/f7/28/77a076f1fa8cbeda61aca712815d04d7a32435f04a26a2dd7b\nSuccessfully built prettytable\nInstalling collected packages: sqlparse, prettytable, ipython-sql\nSuccessfully installed ipython-sql-0.4.1 prettytable-0.7.2 sqlparse-0.4.3\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "%load_ext sql", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "dsn_hostname = \"824dfd4d-99de-440d-9991-629c01b3832d.bs2io90l08kqb1od8lcg.databases.appdomain.cloud\" # e.g.: \"54a2f15b-5c0f-46df-8954-7e38e612c2bd.c1ogj3sd0tgtu0lqde00.databases.appdomain.cloud\"\ndsn_uid = \"wbm69244\"        # e.g. \"abc12345\"\ndsn_pwd = \"nUP2KpGyQ8uJ30yD\"      # e.g. \"7dBZ3wWt9XN6$o0J\"\n\ndsn_driver = \"{IBM DB2 ODBC DRIVER}\"\ndsn_database = \"BLUDB\"            # e.g. \"BLUDB\"\ndsn_port = \"30119\"                # e.g. \"32733\" \ndsn_protocol = \"TCPIP\"            # i.e. \"TCPIP\"\ndsn_security = \"SSL\"              #i.e. \"SSL\"", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Create the dsn connection string\ndsn = (\n    \"DRIVER={0};\"\n    \"DATABASE={1};\"\n    \"HOSTNAME={2};\"\n    \"PORT={3};\"\n    \"PROTOCOL={4};\"\n    \"UID={5};\"\n    \"PWD={6};\"\n    \"SECURITY={7};\").format(dsn_driver, dsn_database, dsn_hostname, dsn_port, dsn_protocol, dsn_uid, dsn_pwd,dsn_security)\n\n#print the connection string to check correct values are specified\nprint(dsn)", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "DRIVER={IBM DB2 ODBC DRIVER};DATABASE=BLUDB;HOSTNAME=824dfd4d-99de-440d-9991-629c01b3832d.bs2io90l08kqb1od8lcg.databases.appdomain.cloud;PORT=30119;PROTOCOL=TCPIP;UID=wbm69244;PWD=nUP2KpGyQ8uJ30yD;SECURITY=SSL;\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#Create database connection\nimport ibm_db\nimport ibm_db_dbi\nimport ibm_db_sa\n\ntry:\n    conn = ibm_db.connect(dsn, \"\", \"\")\n    print (\"Connected to database: \", dsn_database, \"as user: \", dsn_uid, \"on host: \", dsn_hostname)\n\nexcept:\n    print (\"Unable to connect: \", ibm_db.conn_errormsg() )", "execution_count": 11, "outputs": [{"output_type": "stream", "text": "Connected to database:  BLUDB as user:  wbm69244 on host:  824dfd4d-99de-440d-9991-629c01b3832d.bs2io90l08kqb1od8lcg.databases.appdomain.cloud\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "!pip install --upgrade ibm_db\n!pip install --upgrade ibm_db_sa\n!pip install --upgrade SQLAlchemy\n\nimport ibm_db\nimport ibm_db_sa\nimport sqlalchemy\n\n%load_ext sql", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: ibm_db in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (3.1.0)\nCollecting ibm_db\n  Downloading ibm_db-3.1.3.tar.gz (1.4 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.4 MB 22.5 MB/s eta 0:00:01\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: ibm-db\n  Building wheel for ibm-db (PEP 517) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ibm-db: filename=ibm_db-3.1.3-cp39-cp39-linux_x86_64.whl size=385913 sha256=a18967b0cdc3497a5a938338a8cf36c62e3088501379877c981f66f11d1c607b\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/3d/6e/19/64e70ce3dde2ccda5c9b35bd6a313a39e46f6af0222c75cc5f\nSuccessfully built ibm-db\nInstalling collected packages: ibm-db\n  Attempting uninstall: ibm-db\n    Found existing installation: ibm-db 3.1.0\n    Uninstalling ibm-db-3.1.0:\n      Successfully uninstalled ibm-db-3.1.0\nSuccessfully installed ibm-db-3.1.3\nRequirement already satisfied: ibm_db_sa in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (0.3.3)\nCollecting ibm_db_sa\n  Downloading ibm_db_sa-0.3.8-py3-none-any.whl (30 kB)\nRequirement already satisfied: ibm-db>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_db_sa) (3.1.3)\nRequirement already satisfied: sqlalchemy>=0.7.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm_db_sa) (1.3.24)\nInstalling collected packages: ibm-db-sa\n  Attempting uninstall: ibm-db-sa\n    Found existing installation: ibm-db-sa 0.3.3\n    Uninstalling ibm-db-sa-0.3.3:\n      Successfully uninstalled ibm-db-sa-0.3.3\nSuccessfully installed ibm-db-sa-0.3.8\nRequirement already satisfied: SQLAlchemy in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (1.3.24)\nCollecting SQLAlchemy\n  Using cached SQLAlchemy-1.4.42-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from SQLAlchemy) (1.1.3.post0)\nInstalling collected packages: SQLAlchemy\n  Attempting uninstall: SQLAlchemy\n    Found existing installation: SQLAlchemy 1.3.24\n    Uninstalling SQLAlchemy-1.3.24:\n      Successfully uninstalled SQLAlchemy-1.3.24\nSuccessfully installed SQLAlchemy-1.4.42\nThe sql extension is already loaded. To reload it, use:\n  %reload_ext sql\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Remember the connection string is of the format:\n# %sql ibm_db_sa://my-username:my-password@hostname:port/BLUDB?security=SSL\n# Enter the connection string for your Db2 on Cloud database instance below\n# i.e. copy after db2:// from the URI string in Service Credentials of your Db2 instance. Remove the double quotes at the end.\n%sql ibm_db_sa://wbm69244:nUP2KpGyQ8uJ30yD@824dfd4d-99de-440d-9991-629c01b3832d.bs2io90l08kqb1od8lcg.databases.appdomain.cloud:30119/BLUDB?security=SSL", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "Connection info needed in SQLAlchemy format, example:\n               postgresql://username:password@hostname/dbname\n               or an existing connection: dict_keys([])\n'sqlalchemy.cimmutabledict.immutabledict' object does not support item deletion\nConnection info needed in SQLAlchemy format, example:\n               postgresql://username:password@hostname/dbname\n               or an existing connection: dict_keys([])\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Store the dataset in a Table\n\n##### In many cases the dataset to be analyzed is available as a .CSV (comma separated values) file, perhaps on the internet. To analyze the data using SQL, it first needs to be stored in the database.\n\n##### We will first read the dataset source .CSV from the internet into pandas dataframe\n\n##### Then we need to create a table in our Db2 database to store the dataset. The PERSIST command in SQL \"magic\" simplifies the process of table creation and writing the data from a `pandas` dataframe into the table\n"}, {"metadata": {}, "cell_type": "code", "source": "import pandas\nchicago_socioeconomic_data = pandas.read_csv('https://data.cityofchicago.org/resource/jcxq-k9xf.csv')\nchicago_socioeconomic_data.describe()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# command was wrong, check here https://stackoverflow.com/questions/65633362/sql-persist-command-is-giving-an-error-in-ibm-watson-studio-jupyter-notebook\n%sql --persist chicago_socioeconomic_data", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "##### You can verify that the table creation was successful by making a basic query like:\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Problems\n\n### Problem 1\n\n##### How many rows are in the dataset?\n"}, {"metadata": {}, "cell_type": "code", "source": "%sql SELECT COUNT(*) FROM chicago_socioeconomic_data;", "execution_count": 13, "outputs": [{"output_type": "stream", "text": "Environment variable $DATABASE_URL not set, and no connect string given.\nConnection info needed in SQLAlchemy format, example:\n               postgresql://username:password@hostname/dbname\n               or an existing connection: dict_keys([])\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<details><summary>Click here for the solution</summary>\n\n```python\n%sql SELECT COUNT(*) FROM chicago_socioeconomic_data;\n\nCorrect answer: 78\n```\n\n</details>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Problem 2\n\n##### How many community areas in Chicago have a hardship index greater than 50.0?\n"}, {"metadata": {"tags": []}, "cell_type": "code", "source": "%sql select count(ca) from chicago_socioeconomic_data where hardship_index > 50.0;", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<details><summary>Click here for the solution</summary>\n\n```python\n%sql SELECT COUNT(*) FROM chicago_socioeconomic_data WHERE hardship_index > 50.0;\n\nCorrect answer: 38\n```\n\n</details>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Problem 3\n\n##### What is the maximum value of hardship index in this dataset?\n"}, {"metadata": {"tags": []}, "cell_type": "code", "source": "%sql select max(hardship_index) from chicago_socioeconomic_data;", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<details><summary>Click here for the solution</summary>\n\n```python\n%sql SELECT MAX(hardship_index) FROM chicago_socioeconomic_data;\n\nCorrect answer: 98.0\n```\n\n</details>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Problem 4\n\n##### Which community area which has the highest hardship index?\n"}, {"metadata": {"tags": []}, "cell_type": "code", "source": "%sql select community_area_name from chicago_socioeconomic_data where hardship_index = (select max(hardship_index) from chicago_socioeconomic_data);", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<details><summary>Click here for the solution</summary>\n\n```python\n#We can use the result of the last query to as an input to this query:\n%sql SELECT community_area_name FROM chicago_socioeconomic_data where hardship_index=98.0\n\n#or another option:\n%sql SELECT community_area_name FROM chicago_socioeconomic_data ORDER BY hardship_index DESC NULLS LAST FETCH FIRST ROW ONLY;\n\n#or you can use a sub-query to determine the max hardship index:\n%sql select community_area_name from chicago_socioeconomic_data where hardship_index = ( select max(hardship_index) from chicago_socioeconomic_data ) \n\nCorrect answer: 'Riverdale'\n    \n```\n\n</details>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Problem 5\n\n##### Which Chicago community areas have per-capita incomes greater than $60,000?\n"}, {"metadata": {"tags": []}, "cell_type": "code", "source": "%sql select community_area_name, per_capita_income_ from chicago_socioeconomic_data where per_capita_income_ > 60000;\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<details><summary>Click here for the solution</summary>\n\n```python\n%sql SELECT community_area_name FROM chicago_socioeconomic_data WHERE per_capita_income_ > 60000;\n\nCorrect answer:Lake View,Lincoln Park, Near North Side, Loop\n    \n```\n\n</details>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Problem 6\n\n##### Create a scatter plot using the variables `per_capita_income_` and `hardship_index`. Explain the correlation between the two variables.\n"}, {"metadata": {}, "cell_type": "code", "source": "import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nplot = sns.scatterplot(x='per_capita_income_', y='hardship_index', data=chicago_socioeconomic_data, hue='ca')\nplt.title(\"Relationship of Per Capita Income vs Hardship Index\")\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<details><summary>Click here for the solution</summary>\n\n```python\n# if the import command gives ModuleNotFoundError: No module named 'seaborn'\n# then uncomment the following line i.e. delete the # to install the seaborn package \n# !pip install seaborn==0.9.0\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nincome_vs_hardship = %sql SELECT per_capita_income_, hardship_index FROM chicago_socioeconomic_data;\nplot = sns.jointplot(x='per_capita_income_',y='hardship_index', data=income_vs_hardship.DataFrame())\n\nCorrect answer:You can see that as Per Capita Income rises as the Hardship Index decreases. We see that the points on the scatter plot are somewhat closer to a straight line in the negative direction, so we have a negative correlation between the two variables. \n    \n```\n\n</details>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "| We can conclude that at higher levels of income, much lower hardship levels are evidenced"}, {"metadata": {}, "cell_type": "code", "source": "# Close the connection!\nibm_db.close(conn)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Conclusion\n\n##### Now that you know how to do basic exploratory data analysis using SQL and python visualization tools, you can further explore this dataset to see how the variable `per_capita_income_` is related to `percent_households_below_poverty` and `percent_aged_16_unemployed`. Try to create interesting visualizations!\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Summary\n\n##### In this lab you learned how to store a real world data set from the internet in a database (Db2 on IBM Cloud), gain insights into data using SQL queries. You also visualized a portion of the data in the database to see what story it tells.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Author\n\n<a href=\"https://www.linkedin.com/in/ravahuja/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDB0201ENSkillsNetwork20127838-2022-01-01\" target=\"_blank\">Rav Ahuja</a>\n\n## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By    | Change Description                 |\n| ----------------- | ------- | ------------- | ---------------------------------- |\n| 2021-11-17        | 2.3     | Lakshmi       | Updated library                    |\n| 2021-07-09        | 2.2     | Malika        | Updated connection string          |\n| 2021-05-06        | 2.1     | Malika Singla | Added libraries                    |\n| 2020-08-28        | 2.0     | Lavanya       | Moved lab to course repo in GitLab |\n\n<hr>\n\n## <h3 align=\"center\"> \u00a9 IBM Corporation 2020. All rights reserved. <h3/>\n"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "widgets": {"state": {}, "version": "1.1.2"}}, "nbformat": 4, "nbformat_minor": 4}